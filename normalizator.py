import string

from pymorphy3 import MorphAnalyzer

STOPWORDS = [
    "и",
    "в",
    "во",
    "не",
    "что",
    "он",
    "на",
    "я",
    "с",
    "со",
    "как",
    "а",
    "то",
    "все",
    "она",
    "так",
    "его",
    "но",
    "да",
    "ты",
    "к",
    "у",
    "же",
    "вы",
    "за",
    "бы",
    "по",
    "только",
    "ее",
    "мне",
    "было",
    "вот",
    "от",
    "меня",
    "еще",
    "нет",
    "о",
    "из",
    "ему",
    "теперь",
    "когда",
    "даже",
    "ну",
    "вдруг",
    "ли",
    "если",
    "уже",
    "или",
    "ни",
    "быть",
    "был",
    "него",
    "до",
    "вас",
    "нибудь",
    "опять",
    "уж",
    "вам",
    "ведь",
    "там",
    "потом",
    "себя",
    "ничего",
    "ей",
    "может",
    "они",
    "тут",
    "где",
    "есть",
    "надо",
    "ней",
    "для",
    "мы",
    "тебя",
    "их",
    "чем",
    "была",
    "сам",
    "чтоб",
    "без",
    "будто",
    "чего",
    "раз",
    "тоже",
    "себе",
    "под",
    "будет",
    "ж",
    "тогда",
    "кто",
    "этот",
    "того",
    "потому",
    "этого",
    "какой",
    "совсем",
    "ним",
    "здесь",
    "этом",
    "один",
    "почти",
    "мой",
    "тем",
    "чтобы",
    "нее",
    "сейчас",
    "были",
    "куда",
    "зачем",
    "всех",
    "никогда",
    "можно",
    "при",
    "наконец",
    "два",
    "об",
    "другой",
    "хоть",
    "после",
    "над",
    "больше",
    "тот",
    "через",
    "эти",
    "нас",
    "про",
    "всего",
    "них",
    "какая",
    "много",
    "разве",
    "три",
    "эту",
    "моя",
    "впрочем",
    "хорошо",
    "свою",
    "этой",
    "перед",
    "иногда",
    "лучше",
    "чуть",
    "том",
    "нельзя",
    "такой",
    "им",
    "более",
    "всегда",
    "конечно",
    "всю",
    "между",
]



class Normalizator:
    morph = MorphAnalyzer()

    def __remove_punctuations(self, text):
        for punctuation in string.punctuation:
            text = text.replace(punctuation, "")
        return text

    def __remove_stopwords(self, words):
        clear_words = []
        for word in words:
            word = word.lower()
            if word not in STOPWORDS:
                clear_words.append(word)

        return clear_words

    def __lematization(self, words):
        lemmatized = []
        for word in words:
            word = self.morph.normal_forms(word)[0]
            lemmatized.append(word)

        return lemmatized

    def normalize(self, text):
        text = self.__remove_punctuations(text)
        clear_words = self.__remove_stopwords(text.split())
        lematized_words = self.__lematization(clear_words)
        text = " ".join(lematized_words)
        return text

    def normalize_list(self, list):
        normalized = []
        for item in list:
            normalized.append(self.normalize(item))
        return normalized